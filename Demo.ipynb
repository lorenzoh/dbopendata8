{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DB Open Data\n",
    "## What value can we derive out of the masses of until now unused video data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A lot of video footage is recorded everyday without being used.\n",
    "We propose some ideas of how it could support existing sensor systems such as Colibri without the need for additional hardware.\n",
    "Inference is possible on-board."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection with Deep Learning\n",
    "We use a Faster-RCNN implementation built on ResNet and trained on the COCO dataset, since it offers a good trade-off between accuracy and inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The architecture\n",
    "![fasterRCNN](demo/faster_rcnn.png)\n",
    "![Doge](demo/doge.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting people"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image 1](demo/demo_image_2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting specific objects\n",
    "\n",
    "### For example, bicycles:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image 1](demo/bicycle.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Load estimation (Video demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video controls>\n",
       "  <source src=\"demo/demo.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video controls>\n",
    "  <source src=\"./demo/demo.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance could be improved by\n",
    "#### - Using better quality surveillance footage\n",
    "#### - Making use of temporal data (tracking)\n",
    "#### - Using own dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further ideas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pose estimation could be used as an in-between step for action recognition which could identify dangerous/unusual behavior"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Image 1](demo/pose_estimation_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "Model\n",
    "- https://github.com/tensorflow/models/tree/master/research/object_detection\n",
    "\n",
    "Images\n",
    "- https://shadowthink.com/images/cv/faster_rcnn.png\n",
    "- http://www.urbanrail.net/eu/it/rom/fotos/A-Inside-CAF-train1.jpg\n",
    "- http://4.bp.blogspot.com/-l1lYK8beVgQ/Ugr5CMO-mxI/AAAAAAAAEVI/SAJeAvN-fWo/s1600/mbta_bike_coach_train_8432.17xtfkqdw0000csccowkc8kw4.c4xtg9uu3r404wggo4ss0ss8s.th.jpeg\n",
    "\n",
    "\n",
    "Videos\n",
    "- https://www.youtube.com/watch?v=UMhNXIPY9V4\n",
    "- https://www.youtube.com/watch?v=pW6nZXeWlGM"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
